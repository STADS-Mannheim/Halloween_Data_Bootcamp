{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing with Pandas - basics\n",
    "\n",
    "<br>\n",
    "\n",
    "Data preprocessing is a crucial step in any data science project. Raw data often contains noise, missing values, and inconsistencies that can affect model performance. This notebook will walk through the process of cleaning, transforming, and visualizing data using the Pandas library in Python. We will also explore visualizations to gain insights from the data and prepare it for analysis or machine learning models.\n",
    "\n",
    "The following steps will guide you through common preprocessing tasks such as handling missing data, duplicates, outliers, encoding categorical variables, and visualizing data trends.\n",
    "\n",
    "#### Agenda\n",
    "\n",
    "##### 2. Loading the Data\n",
    "\n",
    "##### 3. Handling Missing Data\n",
    "\n",
    "##### 4. Handling Duplicates\n",
    "\n",
    "##### 5. Renaming Columns\n",
    "\n",
    "##### 6. Converting Data Types\n",
    "\n",
    "##### 7. Handling Outliers\n",
    "\n",
    "##### 8. Encoding Categorical Data\n",
    "\n",
    "##### 9. Visualizations\n",
    "\n",
    "##### 10. Saving Cleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "In this section, we will load a dataset using Pandas. Pandas provides an easy-to-use interface for reading data from different file formats like CSV, Excel, or SQL databases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example dataset\n",
    "df = sns.load_dataset('iris')\n",
    "\n",
    "# Display first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Missing data is a common issue when working with real-world datasets. Missing values can be caused by data entry errors, unrecorded events, or limitations in the data collection process. It is important to handle missing data carefully, as ignoring it can lead to biased results.\n",
    "\n",
    "In this section, we will check for missing data, and demonstrate different ways to handle it:\n",
    "\n",
    "- Removing rows or columns with missing values.\n",
    "- Filling missing values using methods like the mean, median, or a custom value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, drop rows/columns with missing data, or fill in missing data\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Fill missing values with a specific value (e.g., 0 or mean)\n",
    "#df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Duplicates\n",
    "\n",
    "Duplicates in the dataset can arise from data collection processes that may record the same event multiple times. Removing duplicates is essential to ensure that the dataset reflects unique records.\n",
    "\n",
    "We will explore how to:\n",
    "\n",
    "- Detect duplicates in the dataset.\n",
    "- Remove duplicates to ensure data integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "To make data more understandable or to conform to a specific format, it may be necessary to rename columns. This is especially helpful when working with datasets where column names are unclear or not intuitive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column \n",
    "df_rename = df\n",
    "df_rename.rename(columns={\n",
    "    'sepal_length': 'Sepal_l'}, inplace=True)\n",
    "\n",
    "# Check the updated dataframe\n",
    "df_rename.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data Types\n",
    "\n",
    "Data often needs to be converted to the appropriate data types before analysis. For example, numerical data may sometimes be read in as strings (objects in Pandas), or dates might not be recognized in the correct format.\n",
    "\n",
    "Here, we will explore:\n",
    "\n",
    "- How to inspect the data types of columns.\n",
    "- Convert columns to the appropriate data types (e.g., integers, floats, datetime).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a numerical column to string (just for demonstration)\n",
    "# df['sepal_width'] = df['sepal_width'].astype('str')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n",
    "\n",
    "Outliers are data points that differ significantly from other observations. While outliers may represent genuine deviations, they can also distort analyses and model training. It is important to identify and decide whether to remove or handle them appropriately.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Detect outliers using statistical methods like Z-scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for 'sepal_width'\n",
    "z_scores = stats.zscore(df['sepal_width'])\n",
    "\n",
    "# Remove outliers\n",
    "df_no_outliers = df[(np.abs(z_scores) < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "\n",
    "Many machine learning algorithms cannot work with categorical data directly. Therefore, it is necessary to encode categorical variables into numerical representations. Pandas provides several methods for this, including one-hot encoding.\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- Convert categorical columns into numeric format using one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of species column\n",
    "df_encoded = pd.get_dummies(df, columns=['species'])\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Visualizing data can help uncover patterns, trends, and potential issues in the dataset. It also helps in understanding the relationships between variables, and identifying outliers and distributions.\n",
    "\n",
    "In this section, we will create various types of visualizations:\n",
    "\n",
    "- **Correlation Heatmap**: Visualize relationships between numerical variables.\n",
    "- **Histogram**: Visualize the distribution of values in a specific column.\n",
    "- **Boxplot**: for Multiple Features\n",
    "- **Swarm plot**: shows all the data points for each category, allowing you to see the spread and density of the points.\n",
    "- **FacetGrid**: FacetGrid allows you to create multiple plots of a feature based on different subsets of data. This is useful when you want to explore the data distributions for multiple features across different species.\n",
    "- **Count Plot**: A count plot shows the frequency of each category in a categorical column, such as species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df_encoded.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Iris Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for 'sepal_width'\n",
    "df_encoded['sepal_width'].hist(bins=30)\n",
    "plt.title('Histogram of Sepal Width')\n",
    "plt.xlabel('Sepal Width (cm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for Sepal Length grouped by species\n",
    "sns.boxplot(x='species', y='Sepal_l', data=df)\n",
    "plt.title('Boxplot of Sepal Length by Species')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for Petal Width grouped by species\n",
    "sns.boxplot(x='species', y='petal_width', data=df)\n",
    "plt.title('Boxplot of Petal Width by Species')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm plot for Sepal Width\n",
    "sns.swarmplot(x='species', y='sepal_width', data=df)\n",
    "plt.title('Swarm Plot of Sepal Width by Species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FacetGrid with histograms of Sepal Length for each species\n",
    "g = sns.FacetGrid(df, col='species')\n",
    "g.map(plt.hist, 'Sepal_l', bins=10)\n",
    "plt.show()\n",
    "\n",
    "# FacetGrid with KDE plots of Petal Length for each species\n",
    "g = sns.FacetGrid(df, col='species')\n",
    "g.map(sns.kdeplot, 'petal_length', shade=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot for species\n",
    "sns.countplot(x='species', data=df)\n",
    "plt.title('Count Plot of Species in Iris Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition\n",
    "\n",
    "## Saving the Cleaned Data\n",
    "\n",
    "Once we have cleaned and preprocessed the data, we may want to save the transformed dataset for future use. Pandas provides methods to save the cleaned dataset into different formats, such as CSV, Excel, or even SQL databases.\n",
    "\n",
    "Here, we will demonstrate how to save the cleaned dataset into a new CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset to a new CSV file\n",
    "df_encoded.to_csv('cleaned_iris_dataset.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
